init: basic vgg19 model loading and preprocessing
feat: implement style and content loss functions

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, models
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# 设置设备
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# 图像处理函数
def load_image(image_path, max_size=400, shape=None):
    image = Image.open(image_path).convert('RGB')

    if max(image.size) > max_size:
        size = max_size
    else:
        size = max(image.size)

    if shape is not None:
        size = shape

    in_transform = transforms.Compose([
        transforms.Resize(size),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406),
                             (0.229, 0.224, 0.225))])

    image = in_transform(image).unsqueeze(0)
    return image.to(device)


def im_convert(tensor):
    image = tensor.cpu().clone().detach()
    image = image.numpy().squeeze()
    image = image.transpose(1, 2, 0)
    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))
    image = image.clip(0, 1)
    return image


# 获取特征提取器
def get_features(image, model, layers=None):
    if layers is None:
        layers = {'0': 'conv1_1',
                  '5': 'conv2_1',
                  '10': 'conv3_1',
                  '19': 'conv4_1',
                  '21': 'conv4_2',  # 内容特征
                  '28': 'conv5_1'}

    features = {}
    x = image
    for name, layer in model._modules.items():
        x = layer(x)
        if name in layers:
            features[layers[name]] = x

    return features


# Gram矩阵计算
def gram_matrix(tensor):
    _, d, h, w = tensor.size()
    tensor = tensor.view(d, h * w)
    gram = torch.mm(tensor, tensor.t())
    return gram


# 风格转换主函数
def style_transfer(content_path, style_path, output_path, epochs=1000, alpha=1, beta=1e6):
    # 加载图像
    content = load_image(content_path).to(device)
    style = load_image(style_path, shape=content.shape[-2:]).to(device)

    # 加载预训练的VGG19模型
    vgg = models.vgg19(pretrained=True).features
    for param in vgg.parameters():
        param.requires_grad_(False)
    vgg.to(device)

    # 获取特征
    content_features = get_features(content, vgg)
    style_features = get_features(style, vgg)

    # 计算风格Gram矩阵
    style_grams = {layer: gram_matrix(style_features[layer]) for layer in style_features}

    # 创建目标图像
    target = content.clone().requires_grad_(True).to(device)

    # 优化器
    optimizer = optim.Adam([target], lr=0.5)

    # 训练循环
    for epoch in range(1, epochs + 1):
        target_features = get_features(target, vgg)
        content_loss = torch.mean((target_features['conv4_2'] - content_features['conv4_2']) ** 2)

        style_loss = 0
        for layer in style_grams:
            target_feature = target_features[layer]
            target_gram = gram_matrix(target_feature)
            _, d, h, w = target_feature.shape
            style_gram = style_grams[layer]
            layer_style_loss = torch.mean((target_gram - style_gram) ** 2)
            style_loss += layer_style_loss / (d * h * w)

        total_loss = alpha * content_loss + beta * style_loss

        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()

        if epoch % 50 == 0:
            print(f'Epoch {epoch}/{epochs}, Total Loss: {total_loss.item():.4f}')

    # 保存结果
    result = im_convert(target)
    plt.imsave(output_path, result)
    print(f"结果已保存至: {output_path}")

    # 显示结果
    fig, ax = plt.subplots(1, 3, figsize=(20, 10))

    ax[0].imshow(im_convert(content))
    ax[0].set_title('内容图像')
    ax[0].axis('off')

    ax[1].imshow(im_convert(style))
    ax[1].set_title('风格图像')
    ax[1].axis('off')

    ax[2].imshow(result)
    ax[2].set_title('风格化结果')
    ax[2].axis('off')

    plt.show()

if __name__ == "__main__":
    content_path = r"C:\Users\GH\Desktop\OIP-C (1).webp"  # 替换为内容图像路径
    style_path = r"C:\Users\GH\Desktop\OIP-C.webp"  # 替换为风格图像路径
    output_path = r"C:\Users\GH\Desktop\1.jpg"  # 输出图像路径

    style_transfer(content_path, style_path, output_path, epochs=300)
